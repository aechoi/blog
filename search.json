[
  {
    "objectID": "posts/recreational_math/optimal_groups.html",
    "href": "posts/recreational_math/optimal_groups.html",
    "title": "Optimal Group Project Assignment",
    "section": "",
    "text": "My senior design project was essentially randomly assigned.\nThe professor gave us a list of potential projects and told us to group up and rank our top five. When we got our assignments, I was a bit disappointed and confused because I got a project that I did not list on my preferences (something to do with measuring strain using digital image correlation). Stranger still, there had been other people that wanted our project. The professor said that the decisions were final. When asked, he said he ran a monte carlo simulation and picked the one that looked the best. We‚Äôre not exactly sure what criteria he used, but the result was that many students were suboptimally assigned.\nYears later, I sometimes think of this, and having TA‚Äôd some courses with group projects, I wondered if there was a better way. The following is an approach that uses integer programming.\nSay you have \\(N\\) students and \\(M\\) projects. The goal is to group students to the projects they want in a way that optimizes for some sort of preference. For now, let‚Äôs say every student provides a dissatisfaction score \\(d_{n,m} \\in [0, \\infty)\\) for each project. Each student then has a vector \\(d_n \\in \\mathbb R^M\\), and the entire class can be described using the following matrix. \\[\nD = \\begin{bmatrix}\n| & & | \\\\\nd_{1} & \\cdots & d_{N} \\\\\n| & & |\n\\end{bmatrix}\n\\]\nEach student must be assigned to one project. This can be described using a 1-hot vector, \\(a_n\\in\\mathbb R^m\\), where the 1 corresponds to the assigned project. Again, the entire class can be assigned using a matrix. This will act as our decision variable. \\[\nA = \\begin{bmatrix}\n| & & | \\\\\na_{1} & \\cdots & a_{N} \\\\\n| & & |\n\\end{bmatrix}\n\\] We can set maximum and minimum group sizes by specifying that the sum of the rows of \\(A\\) must be between the bounds.\nFor our objective, let‚Äôs go with minimizing the total dissatisfaction of the class. This can be notated concisely as \\(\\min_A\\ \\text{Tr}(D^\\intercal A)\\). We can run our optimization as follows.\n\nimport cvxpy as cp\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(0)\n\nnum_projects = 50\nnum_students = 200\n\nmin_group_size = 3\nmax_group_size = 5\n\ndissatisfaction_matrix = np.random.rand(num_projects, num_students)\nassignment_matrix = cp.Variable((num_projects, num_students), boolean=True)\n\nobjective = cp.Minimize(cp.trace(dissatisfaction_matrix.T @ assignment_matrix))\n\nconstraints = []\nconstraints += [cp.sum(assignment_matrix, axis=0) == 1]  # each student gets assigned to only 1 project\nconstraints += [cp.sum(assignment_matrix, axis=1) &gt;= min_group_size]\nconstraints += [cp.sum(assignment_matrix, axis=1) &lt;= max_group_size]\n\nproblem = cp.Problem(objective, constraints)\nproblem.solve()\n\nstudent_dissatisfaction = np.diag(dissatisfaction_matrix.T @ assignment_matrix.value)\nprint(f\"The most dissatisfaction a student has is {np.max(student_dissatisfaction):.2f}/1.0\")\n\nThe most dissatisfaction a student has is 0.11/1.0\n\n\nThat‚Äôs pretty good, but this doesn‚Äôt yet solve our problem. It‚Äôs unreasonable for a student to provide an absolute score for each project. Asking them to pick and rank their top five is much more reasonable. There are many ways you could map a list of five selections to dissatisfaction. One way is to assign constant values to the selections (say, 0 dissatisfaction for your top choice, 0.1 for your second, etc). Then, pick some large value for all omitted projects.\n\nnum_ranks = 5\nomit_cost = 10\n\n# generate rankings from some underlying absolute total ranking\nabsolute_rankings = np.random.rand(num_projects, num_students)\nrankings = np.argsort(absolute_rankings, axis=0)\ntrunc_ranks = rankings[:num_ranks, :]\n\ndissatisfaction_matrix = np.zeros((num_projects, num_students)) + omit_cost\nstudent_vec = np.arange(num_students)\nfor idx, rank in enumerate(trunc_ranks):\n    dissatisfaction_matrix[rank, student_vec] = idx\ndissatisfaction_matrix /= omit_cost # normalize\n\nobjective = cp.Minimize(cp.trace(dissatisfaction_matrix.T @ assignment_matrix))\n\nproblem = cp.Problem(objective, constraints)\nproblem.solve()\n\nstudent_dissatisfaction = np.diag(dissatisfaction_matrix.T @ assignment_matrix.value)\nprint(f\"The most dissatisfaction a student has is {np.max(student_dissatisfaction):.2f}/1.0\")\n\nThe most dissatisfaction a student has is 0.20/1.0\n\n\nThis still works. We know that no one was assigned a project they didn‚Äôt like because the most dissatisfaction is less than 1. However, maybe we just got lucky. We‚Äôre assigning uniformly random preferences for everyone, so it seems likely you‚Äôd be able to get everyone something that they like.\nLet‚Äôs assume that the popularity of certain projects follows a sort of Zipfian distribution.\n\ndef zipf_pmf(k, N):\n    \"\"\"Return the value of a Zipf probability mass function\"\"\"\n    return 1 / k * 1 / np.sum(1 / np.arange(1, num_projects + 1))\n\nproject_probabilities = zipf_pmf(np.arange(1, num_projects + 1), num_projects)\nfig, ax = plt.subplots()\nax.bar(np.arange(num_projects), project_probabilities)\nax.set_ylabel(\"Probability\")\nax.set_xlabel(\"Project Index\")\n_ = ax.set_title(\"Probability of Picking a Project\")\n\n\n\n\n\n\n\n\nWe‚Äôll assume that students populate their preference list by picking from this distribution without replacement.\n\ntrunc_ranks = []\nfor _ in range(num_students):\n    trunc_ranks.append(np.random.choice(np.arange(num_projects), 5, replace=False, p=project_probabilities))\n\ntrunc_ranks = np.asarray(trunc_ranks).T\n\nNow we can solve as before.\n\ndissatisfaction_matrix = np.zeros((num_projects, num_students)) + omit_cost\nstudent_vec = np.arange(num_students)\nfor idx, rank in enumerate(trunc_ranks):\n    dissatisfaction_matrix[rank, student_vec] = idx\ndissatisfaction_matrix /= omit_cost # normalize\n\nobjective = cp.Minimize(cp.trace(dissatisfaction_matrix.T @ assignment_matrix))\n\nproblem = cp.Problem(objective, constraints)\nproblem.solve()\n\nstudent_dissatisfaction = np.diag(dissatisfaction_matrix.T @ assignment_matrix.value)\nprint(f\"The most dissatisfaction a student has is {np.max(student_dissatisfaction):.2f}/1.0\")\n\nThe most dissatisfaction a student has is 0.40/1.0\n\n\nAs expected, the worst case dissatisfaction did go up. But, you know what I can‚Äôt get over?\n\nprint(f\"Number of students that didn't get anything on their list: {np.sum(student_dissatisfaction == 1)}.\")\n\nNumber of students that didn't get anything on their list: 0."
  },
  {
    "objectID": "posts/engineering/henry/henry.html",
    "href": "posts/engineering/henry/henry.html",
    "title": "Animatronic ‚ÄúHenry‚Äù",
    "section": "",
    "text": "I made a head tracked desktop animatronic.\nOn streaming sites like Twitch or YouTube, there has been an increasing number of ‚ÄúV-Tuber‚Äù [Virtual YouTuber] entertainers. These typically consist of a streamer controlling a virtual avatar via motion tracking. I wanted to take the same idea but control a physical avatar using a similar method.\nBelow is a demo of what I ended up with. His name is Henry.\n\nI started by defining some of the requirements including the types of motions I wanted Henry to be capable of. Looking side to side and up/down were needed, but roll isn‚Äôt a very natural thing for your neck to do. I also wanted a face that was expressive enough to convey some basic emotions while being simple enough to be controlled by an Arduino that I had lying around.\nI also needed the face to look fine on camera. LEDs behind a thin two layer 3D print provided a soft, diffuse light while providing a simple way to structurally hold the LEDs.\n\n\n\n\n\n\nA closeup of Henry‚Äôs face\n\n\n\n\n\n\n\nA closer up\n\n\n\n\n\nAfter experimenting a bit, I made the following CAD models in SolidWorks to begin printing of the parts (Ender 3).\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore soldering things together, I tested things by first jumpering all the connections to a bread board. The circuitry is just hooking up some servos and LEDs, so there‚Äôs not much to it other than selecting some resistor values. I did end up using some logic level fets because I was running out of GPIO pins on the Arduino Uno.\n\n\n\n\n\n\n\n\n\n\nThe Arduino communicated over serial to a python script I had made which does a couple things.\n\nMeasure the RMS of my microphone\nTrack the pose of the user‚Äôs head and extract azimuth/elevation angles\nListen for keyboard commands that switched the facial expressions (couldn‚Äôt get emotion recognition working consistently enough)\n\nAfter validating that everything was working properly, I made two PCBs (using KiCad), one for Henry‚Äôs face and a shield for the Arduino that housed the electronics.\n\n\n\n\n\n\n\n\n\n\nSwapping these in significantly reduced the number of cables that needed to plug into Henry‚Äôs head, making his movements much faster and more natural.\n\n\n\n\n\n\n\n\n\n\nThe final and most difficult part of this project was to decide on whether his smile should be a full smile or a smirk. Honestly, I think the smirk looks better, but I‚Äôve been told it makes it look like his face is just broken ü§∑‚Äç‚ôÇÔ∏è.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEdit History\n\n\n\n\n2025-07-31: Reformatted for new site"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "blog",
    "section": "",
    "text": "Welcome to my blog! Here are recent posts:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptimal Group Project Assignment\n\n\n\noptimization\n\n\n\n\n\n\n\n\n\nJul 31, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nAnimatronic ‚ÄúHenry‚Äù\n\n\n\nhardware\n\n\n\n\n\n\n\n\n\nOct 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating 3D Audio with Head Related Transfer Functions (HRTFs)\n\n\n\nsignal processing\n\n\n\n\n\n\n\n\n\nOct 23, 2023\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Alex Choi",
    "section": "",
    "text": "Hi, I‚Äôm a PhD student at the University of Washington studying robotics and control. Previously I worked at Amazon as an Applied Scientist, and before that as a Mechanical Engineer.\nIn my free time I do recreational math, code, play chess, reschedule D&D sessions, and walk my dog (you can see Isaac‚Äôs ears in the pic)."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Alex Choi",
    "section": "Education",
    "text": "Education\nUniversity of Washington | Seattle, WA\nPhD in Electrical and Computer Engineering | Sep 2024 - Present\nUniversity of Texas | Austin, TX\nBS in Mechanical Engineering | Aug 2015 - May 2019"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Alex Choi",
    "section": "Experience",
    "text": "Experience\nAmazon.com | Seattle, WA\nApplied Scientist II | May 2022 - Jun 2024\nAmazon.com | Seattle, WA\nMechanical Engineer II/I | Aug 2019 - May 2022\nSpaceX | Hawthorne, CA\nVehicle Engineering Intern | May 2018 - Aug 2018\nAmazon.com | Seattle, WA\nProduct Design Engineering Intern | May 2017 - Aug 2017"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "hello",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "posts/recreational_math/head_related_tfs/head_related_tfs.html",
    "href": "posts/recreational_math/head_related_tfs/head_related_tfs.html",
    "title": "Generating 3D Audio with Head Related Transfer Functions (HRTFs)",
    "section": "",
    "text": "I made a script to make regular audio sound 3D\nBack around 2012 I saw this demo on YouTube about a ‚ÄúVirtual Barber Shop‚Äù. When listened to with headphones, the actors are able to move around the listener as if they were in the room with you.\nIt‚Äôs actually still up (at the time of writing). Worth a listen if you‚Äôve never heard it before.\n\nHearing this for the first time was what I imagine it was like for people to see color movies and TV for the first time.\nMore recently (during Covid boredom) I wanted to look more deeply into how this sort of audio could be made and to see if there was a way to do it without buying expensive hardware.\nOften the explanation people give is that this is an example of ‚Äúbinaural audio‚Äù where microphones are placed inside a dummy head (like the one pictured below) so that the differences heard between the left and right ear are interpreted as directions.\n\n\n\n\n\nThis certainly plays a part but is not the whole story. The problem with that explanation is that it doesn‚Äôt explain why you can tell when a sound comes from above or below you. In those cases, the sounds entering your left and right ear could be the exact same yet you can still localize the sound in the correct direction. The same goes for when a sound is directly in front or behind you. Simply adding delay to one side or the other is not sufficient to encode all of the spatial data.\nThe frequency content of the sounds themselves are subject to different transfer functions that are a function of the relative position of the sound origin to your head, the shape and composition of your head, the shape of your ears, the room your in, and a variety of other factors.\nThese Head Related Transfer Functions (HRTFs) can be modeled and measured. In fact there is a convenient online database filled with many examples. Generally these transfer functions are stored as an array of pairs of impulse responses (one for each ear). Convolving these impulse responses with any audio file lets you make the audio sound like it‚Äôs coming from somewhere in space.\nThese impulse responses are generally collected over the surface of multiple spheres at many distances from the listener.\n\n\n\n\n\nBelow is an example implementation I made using Bernsch√ºtz (2013). The code can be found on my github page here.\n\nIn it, I use a method found in Gamper (2013) to search for and interpolate the HRIRs. The method involves triangulating (tetrating?) the space using Delaunay triangulation. Then, given some starting tetrahedron, determine which vertex is furthest from the desired point in space. The tetrahedron that shares the face opposite that vertex is then the next nearest of the neighboring tetrahedrons. This process is continued until the desired point lies within the current tetrahedron.\n\n\n\n\n\nOnce found, the HRIRs at the vertices of that tetrahedron can be interpolated together using barycentric interpolation, providing a smooth transition when the point moves across the space to other tetrahedrons. The audio can now be convolved with the appropriate HRIR.\nWhen I first worked on this project back in 2020, I just had a little GUI that the user could interact with (as seen in the video above). Later on, I wanted to make a more hands-free way to move the audio around that could be used when on a call, streaming, or recording video.\nI implemented some head tracking and mapped the location of the face in the frame to control the source location using OpenCV and MediaPipe. Below is a quick demo. The code can be found on my repo.\n\nUltimately I was hoping that I could prank some of my coworkers in our online meetings, but it turns out most VOIP software streams mono audio to save on network bandwidth.\n\n\n\n\n\n\nEdit History\n\n\n\n\n2025-07-31: Reformatted for new site\n\n\n\n\n\n\n\nReferences\n\nBernsch√ºtz, Benjamin. 2013. ‚ÄúA Spherical Far Field HRIR/HRTF Compilation of the Neumann KU 100.‚Äù In Proceedings of the AIA-DAGA Conference on Acoustics. Merano, Italy. http://audiogroup.web.th-koeln.de/FILES/AIA-DAGA2013_HRIRs.pdf.\n\n\nGamper, Hannes. 2013. ‚ÄúHead-Related Transfer Function Interpolation in Azimuth, Elevation, and Distance.‚Äù The Journal of the Acoustical Society of America 134 (6): 3761‚Äì72. https://doi.org/10.1121/1.4828983."
  }
]