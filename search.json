[
  {
    "objectID": "posts/recreational_math/optimal_groups.html",
    "href": "posts/recreational_math/optimal_groups.html",
    "title": "Optimal Group Project Assignment",
    "section": "",
    "text": "My senior design project was essentially randomly assigned.\nThe professor gave us a list of potential projects and told us to group up and rank our top five. When we got our assignments, I was a bit disappointed and confused because I got a project that I did not list on my preferences (something to do with measuring strain using digital image correlation). Stranger still, there had been other people that wanted our project. The professor said that the decisions were final. When asked, he said he ran a monte carlo simulation and picked the one that looked the best. We‚Äôre not exactly sure what criteria he used, but the result was that many students were suboptimally assigned.\nYears later, I sometimes think of this, and having TA‚Äôd some courses with group projects, I wondered if there was a better way. The following is an approach that uses integer programming.\nSay you have \\(N\\) students and \\(M\\) projects. The goal is to group students to the projects they want in a way that optimizes for some sort of preference. For now, let‚Äôs say every student provides a dissatisfaction score \\(d_{n,m} \\in [0, \\infty)\\) for each project. Each student then has a vector \\(d_n \\in \\mathbb R^M\\), and the entire class can be described using the following matrix. \\[\nD = \\begin{bmatrix}\n| & & | \\\\\nd_{1} & \\cdots & d_{N} \\\\\n| & & |\n\\end{bmatrix}\n\\]\nEach student must be assigned to one project. This can be described using a 1-hot vector, \\(a_n\\in\\mathbb R^m\\), where the 1 corresponds to the assigned project. Again, the entire class can be assigned using a matrix. This will act as our decision variable. \\[\nA = \\begin{bmatrix}\n| & & | \\\\\na_{1} & \\cdots & a_{N} \\\\\n| & & |\n\\end{bmatrix}\n\\] We can set maximum and minimum group sizes by specifying that the sum of the rows of \\(A\\) must be between the bounds.\nFor our objective, let‚Äôs go with minimizing the total dissatisfaction of the class. This can be notated concisely as \\(\\min_A\\ \\text{Tr}(D^\\intercal A)\\). We can run our optimization as follows.\n\nimport cvxpy as cp\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(0)\n\nnum_projects = 50\nnum_students = 200\n\nmin_group_size = 3\nmax_group_size = 5\n\ndissatisfaction_matrix = np.random.rand(num_projects, num_students)\nassignment_matrix = cp.Variable((num_projects, num_students), boolean=True)\n\nobjective = cp.Minimize(cp.trace(dissatisfaction_matrix.T @ assignment_matrix))\n\nconstraints = []\nconstraints += [cp.sum(assignment_matrix, axis=0) == 1]  # each student gets assigned to only 1 project\nconstraints += [cp.sum(assignment_matrix, axis=1) &gt;= min_group_size]\nconstraints += [cp.sum(assignment_matrix, axis=1) &lt;= max_group_size]\n\nproblem = cp.Problem(objective, constraints)\nproblem.solve()\n\nstudent_dissatisfaction = np.diag(dissatisfaction_matrix.T @ assignment_matrix.value)\nprint(f\"The most dissatisfaction a student has is {np.max(student_dissatisfaction):.2f}/1.0\")\n\nThe most dissatisfaction a student has is 0.11/1.0\n\n\nThat‚Äôs pretty good, but this doesn‚Äôt yet solve our problem. It‚Äôs unreasonable for a student to provide an absolute score for each project. Asking them to pick and rank their top five is much more reasonable. There are many ways you could map a list of five selections to dissatisfaction. One way is to assign constant values to the selections (say, 0 dissatisfaction for your top choice, 0.1 for your second, etc). Then, pick some large value for all omitted projects.\n\nnum_ranks = 5\nomit_cost = 10\n\n# generate rankings from some underlying absolute total ranking\nabsolute_rankings = np.random.rand(num_projects, num_students)\nrankings = np.argsort(absolute_rankings, axis=0)\ntrunc_ranks = rankings[:num_ranks, :]\n\ndissatisfaction_matrix = np.zeros((num_projects, num_students)) + omit_cost\nstudent_vec = np.arange(num_students)\nfor idx, rank in enumerate(trunc_ranks):\n    dissatisfaction_matrix[rank, student_vec] = idx\ndissatisfaction_matrix /= omit_cost # normalize\n\nobjective = cp.Minimize(cp.trace(dissatisfaction_matrix.T @ assignment_matrix))\n\nproblem = cp.Problem(objective, constraints)\nproblem.solve()\n\nstudent_dissatisfaction = np.diag(dissatisfaction_matrix.T @ assignment_matrix.value)\nprint(f\"The most dissatisfaction a student has is {np.max(student_dissatisfaction):.2f}/1.0\")\n\nThe most dissatisfaction a student has is 0.20/1.0\n\n\nThis still works. We know that no one was assigned a project they didn‚Äôt like because the most dissatisfaction is less than 1. However, maybe we just got lucky. We‚Äôre assigning uniformly random preferences for everyone, so it seems likely you‚Äôd be able to get everyone something that they like.\nLet‚Äôs assume that the popularity of certain projects follows a sort of Zipfian distribution.\n\ndef zipf_pmf(k, N):\n    \"\"\"Return the value of a Zipf probability mass function\"\"\"\n    return 1 / k * 1 / np.sum(1 / np.arange(1, num_projects + 1))\n\nproject_probabilities = zipf_pmf(np.arange(1, num_projects + 1), num_projects)\nfig, ax = plt.subplots()\nax.bar(np.arange(num_projects), project_probabilities)\nax.set_ylabel(\"Probability\")\nax.set_xlabel(\"Project Index\")\n_ = ax.set_title(\"Probability of Picking a Project\")\n\n\n\n\n\n\n\n\nWe‚Äôll assume that students populate their preference list by picking from this distribution without replacement.\n\ntrunc_ranks = []\nfor _ in range(num_students):\n    trunc_ranks.append(np.random.choice(np.arange(num_projects), 5, replace=False, p=project_probabilities))\n\ntrunc_ranks = np.asarray(trunc_ranks).T\n\nNow we can solve as before.\n\ndissatisfaction_matrix = np.zeros((num_projects, num_students)) + omit_cost\nstudent_vec = np.arange(num_students)\nfor idx, rank in enumerate(trunc_ranks):\n    dissatisfaction_matrix[rank, student_vec] = idx\ndissatisfaction_matrix /= omit_cost # normalize\n\nobjective = cp.Minimize(cp.trace(dissatisfaction_matrix.T @ assignment_matrix))\n\nproblem = cp.Problem(objective, constraints)\nproblem.solve()\n\nstudent_dissatisfaction = np.diag(dissatisfaction_matrix.T @ assignment_matrix.value)\nprint(f\"The most dissatisfaction a student has is {np.max(student_dissatisfaction):.2f}/1.0\")\n\nThe most dissatisfaction a student has is 0.40/1.0\n\n\nAs expected, the worst case dissatisfaction did go up. But, you know what I can‚Äôt get over?\n\nprint(f\"Number of students that didn't get anything on their list: {np.sum(student_dissatisfaction == 1)}.\")\n\nNumber of students that didn't get anything on their list: 0."
  },
  {
    "objectID": "posts/recreational_math/buffon/buffon.html",
    "href": "posts/recreational_math/buffon/buffon.html",
    "title": "A Multidimensional Extension of Buffon‚Äôs Needle Problem",
    "section": "",
    "text": "I made a paper on a multidimensional extension of Buffon‚Äôs needle problem\nIn my free time I wrote this paper on a multidimensional extension of Buffon‚Äôs needle problem. Here it is:\n\nThis browser does not support PDFs. Please download the PDF to view it: &lt;a href=\"buffon_extension.pdf\"&gt;Download PDF&lt;/a&gt;\n\nYou might be asking, ‚ÄúWhy did you decide to write a paper on a multidimensional extension of Buffon‚Äôs needle problem?‚Äù. That‚Äôs a good question. If you want to go straight to the technical stuff skip the next section.\nSo it started because I was doing one of the Jane Street puzzles back in August, specifically this one.\nThe way I went about the solution was realizing that this seemed really similar to the Buffon Needle problem which I had heard about through a Numberphile video from way back. I did some modeling on paper and simulation on python and came to a solution by extending the method used for the Buffon Needle in 2D to 3D. Then I got to thinking that someone must have already derived this for all dimensions and I probably could have saved myself a bunch of time by just looking directly for the multidimensional solution. I searched google scholar, arXiv, Wikipedia, but I couldn‚Äôt find a generalized solution anywhere. So I figured this would be a good exercise in writing a paper.\n\nThe Extension\nI‚Äôm not going to describe everything in the doc because it‚Äôd take too long, but I‚Äôll describe the main points here.\nThe problem statement is as follows. Imagine a space that is tiled by hyperplanes. In 2D this would be regularly spaced horizontal and/or vertical lines, in 3D this would be orthogonal sets of parallel planes, in 4D this would be up to 4 orthogonal sets of parallel 3D volumes, etc. Anything up to an arbitrary D-dimensional space. Now imagine a needle is randomly placed and oriented in that space. Find the probability that the needle crosses more than some number, c, of hyperplanes. To make it trickier, imagine that the needle could be any length, there could be any number of hyperplanes (from N=1 parallel set to N=D parallel sets), and the spacing between the parallel hyperplanes doesn‚Äôt have to be the same for every set.\n\nThe strategy is as follows, model the needle using higher dimensional spherical coordinates, then integrate using the necessary conditions for crossing some number of hyperplanes as the bounds of integration.\nThis gets trickier when there are N&gt;1 hyperplane directions. Mainly because now there are many different combinations of hyperplanes that can be crossed to achieve some number of total crossings. In this case we can use the inclusion-exclusion principle to combine the multiple individual probabilities.\nAfter a lot of calculus you end up with expressions for the probability of crossing. You can compare this to simulated versions of the needle as well. Below are the probabilities of having more than some number of crossings for a single hyperplane.\n\nYou can use algebra to then derive the probability of crossing exactly some number of hyperplanes as well.\n\nBelow are the probabilities with multiple hyperplanes. For this problem there doesn‚Äôt seem to be a closed-form way to represent the probability with elementary functions if the needle is longer than the hyperplane spacing.\n\nYou can find the scripts I used and the .tex files on my github repo here. As of writing this it‚Äôs not fully polished up so fair warning.\n\n\n\n\n\n\nEdit History\n\n\n\n\n2025-07-31: Reformatted for new site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "hello",
    "section": "",
    "text": "Hi, I‚Äôm Alex, you can learn more about me on the about page.\nThis website stores a collection of my personal projects, academic papers, technical demos, or anything else I may have had a part in authoring. Check out the blog for more.\nTo email/contact Alex Choi (me), email contact@alexchoi.me"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Alex Choi",
    "section": "",
    "text": "Hi, I‚Äôm a PhD student at the University of Washington studying robotics and control. Previously I worked at Amazon as an Applied Scientist, and before that as a Mechanical Engineer. Even further back, I co-founded Longhorn Racing Electric, the Formula SAE Electric team at UT Austin.\nIn my free time I do recreational math, code, play chess, reschedule D&D sessions, and walk my dog (you can see Isaac‚Äôs ears in the pic)."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Alex Choi",
    "section": "Education",
    "text": "Education\nUniversity of Washington | Seattle, WA\nPhD in Electrical and Computer Engineering | Sep 2024 - Present\nUniversity of Texas | Austin, TX\nBS in Mechanical Engineering | Aug 2015 - May 2019"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Alex Choi",
    "section": "Experience",
    "text": "Experience\nAmazon.com | Seattle, WA\nApplied Scientist II | May 2022 - Jun 2024\nAmazon.com | Seattle, WA\nMechanical Engineer II/I | Aug 2019 - May 2022\nSpaceX | Hawthorne, CA\nVehicle Engineering Intern | May 2018 - Aug 2018\nAmazon.com | Seattle, WA\nProduct Design Engineering Intern | May 2017 - Aug 2017"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "blog",
    "section": "",
    "text": "Welcome to my blog! Here are recent posts:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptimal Group Project Assignment\n\n\n\noptimization\n\n\n\n\n\n\n\n\n\nJul 31, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nA Multidimensional Extension of Buffon‚Äôs Needle Problem\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nNov 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nAnimatronic ‚ÄúHenry‚Äù\n\n\n\nhardware\n\n\n\n\n\n\n\n\n\nOct 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating 3D Audio with Head Related Transfer Functions (HRTFs)\n\n\n\nsignal processing\n\n\n\n\n\n\n\n\n\nOct 23, 2023\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/engineering/henry/henry.html",
    "href": "posts/engineering/henry/henry.html",
    "title": "Animatronic ‚ÄúHenry‚Äù",
    "section": "",
    "text": "I made a head tracked desktop animatronic.\nOn streaming sites like Twitch or YouTube, there has been an increasing number of ‚ÄúV-Tuber‚Äù [Virtual YouTuber] entertainers. These typically consist of a streamer controlling a virtual avatar via motion tracking. I wanted to take the same idea but control a physical avatar using a similar method.\nBelow is a demo of what I ended up with. His name is Henry.\n\nI started by defining some of the requirements including the types of motions I wanted Henry to be capable of. Looking side to side and up/down were needed, but roll isn‚Äôt a very natural thing for your neck to do. I also wanted a face that was expressive enough to convey some basic emotions while being simple enough to be controlled by an Arduino that I had lying around.\nI also needed the face to look fine on camera. LEDs behind a thin two layer 3D print provided a soft, diffuse light while providing a simple way to structurally hold the LEDs.\n\n\n\n\n\n\nA closeup of Henry‚Äôs face\n\n\n\n\n\n\n\nA closer up\n\n\n\n\n\nAfter experimenting a bit, I made the following CAD models in SolidWorks to begin printing of the parts (Ender 3).\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore soldering things together, I tested things by first jumpering all the connections to a breadboard. The circuitry is just hooking up some servos and LEDs, so there‚Äôs not much to it other than selecting some resistor values. I did end up using some logic level fets because I was running out of GPIO pins on the Arduino Uno.\n\n\n\n\n\n\n\n\n\n\nThe Arduino communicated over serial to a python script I had made which does a couple things.\n\nMeasure the RMS of my microphone\nTrack the pose of the user‚Äôs head and extract azimuth/elevation angles\nListen for keyboard commands that switched the facial expressions (couldn‚Äôt get emotion recognition working consistently enough)\n\nAfter validating that everything was working properly, I made two PCBs (using KiCad), one for Henry‚Äôs face and a shield for the Arduino that housed the electronics.\n\n\n\n\n\n\n\n\n\n\nSwapping these in significantly reduced the number of cables that needed to plug into Henry‚Äôs head, making his movements much faster and more natural.\n\n\n\n\n\n\n\n\n\n\nThe final and most difficult part of this project was to decide on whether his smile should be a full smile or a smirk. Honestly, I think the smirk looks better, but I‚Äôve been told it makes it look like his face is just broken ü§∑‚Äç‚ôÇÔ∏è.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEdit History\n\n\n\n\n2025-07-31: Reformatted for new site"
  },
  {
    "objectID": "posts/recreational_math/head_related_tfs/head_related_tfs.html",
    "href": "posts/recreational_math/head_related_tfs/head_related_tfs.html",
    "title": "Generating 3D Audio with Head Related Transfer Functions (HRTFs)",
    "section": "",
    "text": "I made a script to make regular audio sound 3D\nBack around 2012 I saw this demo on YouTube about a ‚ÄúVirtual Barber Shop‚Äù. When listened to with headphones, the actors are able to move around the listener as if they were in the room with you.\nIt‚Äôs actually still up (at the time of writing). Worth a listen if you‚Äôve never heard it before.\nHearing this for the first time was what I imagine it was like for people to see color movies and TV for the first time.\nMore recently (during Covid boredom) I wanted to look more deeply into how this sort of audio could be made and to see if there was a way to do it without buying expensive hardware.\nOften the explanation people give is that this is an example of ‚Äúbinaural audio‚Äù where microphones are placed inside a dummy head (like the one pictured below) so that the differences heard between the left and right ear are interpreted as directions.\nThis certainly plays a part but is not the whole story. The problem with that explanation is that it doesn‚Äôt explain why you can tell when a sound comes from above or below you. In those cases, the sounds entering your left and right ear could be the exact same yet you can still localize the sound in the correct direction. The same goes for when a sound is directly in front or behind you. Simply adding delay to one side or the other is not sufficient to encode all of the spatial data.\nThe frequency content of the sounds themselves are subject to different transfer functions that are a function of the relative position of the sound origin to your head, the shape and composition of your head, the shape of your ears, the room your in, and a variety of other factors.\nThese Head Related Transfer Functions (HRTFs) can be modeled and measured. In fact there is a convenient online database filled with many examples. Generally these transfer functions are stored as an array of pairs of impulse responses (one for each ear). Convolving these impulse responses with any audio file lets you make the audio sound like it‚Äôs coming from somewhere in space.\nThese impulse responses are generally collected over the surface of multiple spheres at many distances from the listener.\nBelow is an example implementation I made using Bernsch√ºtz (2013). The code can be found on my github page here.\nIn it, I use a method found in Gamper (2013) to search for and interpolate the HRIRs. The method involves triangulating (tetrating?) the space using Delaunay triangulation. Then, given some starting tetrahedron, determine which vertex is furthest from the desired point in space. The tetrahedron that shares the face opposite that vertex is then the next nearest of the neighboring tetrahedrons. This process is continued until the desired point lies within the current tetrahedron.\nOnce found, the HRIRs at the vertices of that tetrahedron can be interpolated together using barycentric interpolation, providing a smooth transition when the point moves across the space to other tetrahedrons. The audio can now be convolved with the appropriate HRIR.\nWhen I first worked on this project back in 2020, I just had a little GUI that the user could interact with (as seen in the video above). Later on, I wanted to make a more hands-free way to move the audio around that could be used when on a call, streaming, or recording video.\nI implemented some head tracking and mapped the location of the face in the frame to control the source location using OpenCV and MediaPipe. Below is a quick demo. The code can be found on my repo.\nUltimately I was hoping that I could prank some of my coworkers in our online meetings, but it turns out most VOIP software streams mono audio to save on network bandwidth."
  },
  {
    "objectID": "posts/recreational_math/head_related_tfs/head_related_tfs.html#references",
    "href": "posts/recreational_math/head_related_tfs/head_related_tfs.html#references",
    "title": "Generating 3D Audio with Head Related Transfer Functions (HRTFs)",
    "section": "References",
    "text": "References\n\nBernsch√ºtz, Benjamin. 2013. ‚ÄúA Spherical Far Field HRIR/HRTF Compilation of the Neumann KU 100.‚Äù In Proceedings of the AIA-DAGA Conference on Acoustics. Merano, Italy. http://audiogroup.web.th-koeln.de/FILES/AIA-DAGA2013_HRIRs.pdf.\n\n\nGamper, Hannes. 2013. ‚ÄúHead-Related Transfer Function Interpolation in Azimuth, Elevation, and Distance.‚Äù The Journal of the Acoustical Society of America 134 (6): 3761‚Äì72. https://doi.org/10.1121/1.4828983."
  }
]